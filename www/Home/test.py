import requests
from bs4 import BeautifulSoup
import re
import mysql.connector

def get_psrid_list():
    """
    å¾å­¸æ ¡åˆ—è¡¨é é¢è‡ªå‹•æŠ“å–æ‰€æœ‰ psridï¼ˆå­¸æ ¡ä»£ç¢¼ï¼‰ï¼Œä¸¦æ’é™¤ã€Œå…¨åœ‹æŠ€å°ˆæ ¡é™¢ã€ã€‚
    """
    list_url = "https://www.techadmi.edu.tw/comms.php?comid=comd06"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    response = requests.get(list_url, headers=headers)
    if response.status_code != 200:
        print(f"âŒ ç„¡æ³•è«‹æ±‚ {list_url}ï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}")
        return []

    response.encoding = response.apparent_encoding
    soup = BeautifulSoup(response.text, "html.parser")

    psrid_set = set()
    
    # éæ­·æ‰€æœ‰ a æ¨™ç±¤
    for a in soup.find_all("a", href=True):
        school_name = a.get_text(strip=True)
        
        # å…ˆæ’é™¤æ‰å«æœ‰ã€Œå…¨åœ‹æŠ€å°ˆæ ¡é™¢ã€çš„é€£çµï¼ˆå¦‚æœ a æ¨™ç±¤æ–‡å­—å‰›å¥½å«æ­¤å­—ä¸²ï¼‰
        if "å…¨åœ‹æŠ€å°ˆæ ¡é™¢" in school_name:
            continue

        match = re.search(r"psrid=(\d+)", a["href"])
        if match:
            psrid = match.group(1)
            psrid_set.add(psrid)

    return sorted(list(psrid_set), key=int)

def scrape_school_data(psrid):
    """
    æ ¹æ“š psrid æŠ“å–å­¸æ ¡åç¨±ã€ç§‘ç³»ã€åœ°å€ã€å®˜ç¶²ç¶²å€ã€‚
    """
    url = f"https://www.techadmi.edu.tw/school.php?psrid={psrid}&ar=2"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f"âŒ ç„¡æ³•è«‹æ±‚ {url}ï¼ŒHTTP ç‹€æ…‹ç¢¼: {response.status_code}")
        return []

    response.encoding = response.apparent_encoding
    soup = BeautifulSoup(response.text, "html.parser")

    print(f"âœ… æˆåŠŸè«‹æ±‚ {url}")

    # æŠ“å–å­¸æ ¡åç¨±
    school_title_tag = soup.find("h2")
    school_name = school_title_tag.get_text(strip=True) if school_title_tag else "âŒ å­¸æ ¡åç¨±æœªæ‰¾åˆ°"

    # å¦‚æœæ˜¯ã€Œå…¨åœ‹æŠ€å°ˆæ ¡é™¢ã€ï¼Œå°±ç›´æ¥è·³é
    if "å…¨åœ‹æŠ€å°ˆæ ¡é™¢" in school_name:
        print(f"ğŸš« è·³é psrid={psrid}ï¼Œå› ç‚ºå®ƒæ˜¯ã€Œ{school_name}ã€")
        return []

    # æŠ“å–åœ°å€
    address_list = []
    address_tag = soup.find("p", class_="full-address")
    if address_tag:
        for br in address_tag.find_all("br"):
            br.replace_with("\n")
        address_list = address_tag.get_text("\n", strip=True).split("\n")
    address = " / ".join(address_list) if address_list else "âŒ åœ°å€æœªæ‰¾åˆ°"

    # æŠ“å–å­¸æ ¡å®˜ç¶²
    official_site = "âŒ å®˜æ–¹ç¶²ç«™æœªæ‰¾åˆ°"
    official_link_tag = soup.select_one("div.side-block a.btn1[href]")
    if official_link_tag:
        official_site = official_link_tag["href"].strip()

    # æŠ“å–ç§‘ç³»åˆ—è¡¨
    department_list = []
    dep_tags = soup.select("div.phase-contents div.links3 a")
    for dep_tag in dep_tags:
        department_list.append(dep_tag.get_text(strip=True))
    if not department_list:
        department_list.append("âŒ æœªæ‰¾åˆ°ç§‘ç³»")

    # çµ„åˆçµæœ
    results = []
    for dep in department_list:
        results.append([school_name, dep, address, official_site])

    return results
def insert_into_db(data):
    """
    å°‡æœ€çµ‚çµæœå¯«å…¥ MySQL è³‡æ–™åº«ã€‚
    data ç‚ºä¸€å€‹ listï¼Œå…¶ä¸­æ¯å€‹å…ƒç´ éƒ½æ˜¯ [school_name, department, address, official_site]ã€‚
    """
    try:
        connection = mysql.connector.connect(
            host="127.0.0.1",
            user="HCHJ",
            password="xx435kKHq",
            database="HCHJ",
            charset="utf8mb4"  # æŒ‡å®šç·¨ç¢¼
        )
        cursor = connection.cursor()
        insert_query = """
        INSERT INTO test (school_name, department, address, official_site)
        VALUES (%s, %s, %s, %s)
        """
        # ä½¿ç”¨ executemany ä¸€æ¬¡æ€§æ’å…¥å¤šç­†è³‡æ–™
        cursor.executemany(insert_query, data)
        connection.commit()
        print("âœ… è³‡æ–™å·²æˆåŠŸå¯«å…¥è³‡æ–™åº«ï¼")
    except mysql.connector.Error as err:
        print("âŒ è³‡æ–™åº«éŒ¯èª¤:", err)
    finally:
        if connection.is_connected():
            cursor.close()
            connection.close()

def main():
    # 1. æŠ“å–æ‰€æœ‰ psrid
    psrid_list = get_psrid_list()
    print("âœ… æ‰¾åˆ°çš„å­¸æ ¡ä»£ç¢¼ (psrid)ï¼š", psrid_list)

    all_data = []
    
    # 2. éæ­·æ‰€æœ‰ psridï¼Œçˆ¬å–å­¸æ ¡è³‡è¨Š
    for psrid in psrid_list:
        print(f"ğŸ“Œ æ­£åœ¨è™•ç†å­¸æ ¡ psrid = {psrid} ...")
        school_data = scrape_school_data(psrid)
        all_data.extend(school_data)
    
    # 3. è¼¸å‡ºçµæœ (å¯å…ˆåœ¨ console å°å‡ºç¢ºèª)
    print("\nğŸ“Œ æœ€çµ‚çµæœï¼š")
    for item in all_data:
        print("å­¸æ ¡åç¨±:", item[0])
        print("ç§‘ç³»:", item[1])
        print("åœ°å€:", item[2])
        print("å®˜æ–¹ç¶²ç«™:", item[3])
        print("-" * 50)

    # 4. å¯«å…¥è³‡æ–™åº«
    if all_data:
        insert_into_db(all_data)

if __name__ == "__main__":
    main()
